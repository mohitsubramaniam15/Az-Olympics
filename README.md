# Azure-Olympics
## üìå Overview

This project implements an end-to-end data pipeline using Azure services and Delta Lake for analyzing Olympics data. The data processing follows the Medallion architecture (Bronze, Silver, and Gold layers) to ensure data integrity, version control, and efficient transformations. The final insights are visualized in Power BI with advanced DAX measures.

---

## üèÜ Problem Statement

Analyzing Olympics data requires a structured pipeline that ensures accuracy, version control, and scalable processing. The goal of this project is to:

- Efficiently ingest and clean raw Olympics data.
- Process and transform the data for insightful analysis.
- Generate key performance metrics using DAX.
- Visualize trends such as country-wise medal distribution and gender-based participation.

---

## üìä Analysis & Key Insights

- **Medal Distribution**: The United States won the most gold medals, followed closely by China and Japan.
- **Gender Participation**: Athletics had the highest gender-balanced participation, while artistic swimming was dominated by female athletes.
- **Top Performing Countries**: Countries like the U.S., China, and Great Britain consistently lead in total medal counts.
- **Trend Analysis**: Power BI dashboards allow dynamic exploration of trends across disciplines and years.

---

## üöÄ Tech Stack

- **Cloud Services**: Azure Data Factory, Azure Data Lake, Databricks
- **Processing**: PySpark, SQL, Delta Lake
- **Visualization**: Power BI, DAX
- **Data Formats**: CSV, Parquet, JSON

---

## üèóÔ∏è Architecture

### **Medallion Architecture Implementation**

#### **Bronze Layer (Raw Data):**
- Data ingestion from Azure Data Lake (CSV format).
- Storage in a raw zone without modifications.

#### **Silver Layer (Cleansed Data):**
- Data transformation using PySpark.
- Casting data types, handling missing values, and schema enforcement.
- Stored in Parquet format.

#### **Gold Layer (Analytical Data):**
- Aggregation and business logic implementation.
- Optimized data for Power BI visualization.

```python
# Writing data to Delta Lake in Gold Layer

df_ath.write.format('delta').mode('append').option('path', f'{gold}/Delta/Athletes').saveAsTable('Athlete')
df_Coaches.write.format('delta').mode('append').option('path', f'{gold}/Delta/Coaches').saveAsTable('Coaches')
df_EntriesGender.write.format('delta').mode('append').option('path', f'{gold}/Delta/EntriesGender').saveAsTable('EntriesGender')
df_Medals_1.write.format('delta').mode('append').option('path', f'{gold}/Delta/Medals').saveAsTable('Medals')
df_Teams.write.format('delta').mode('append').option('path', f'{gold}/Delta/Teams').saveAsTable('Teams')
```

---

## üõ†Ô∏è Delta Lake: Time Travel, Versioning & ACID Transactions

### **Time Travel in Delta Lake**
Delta Lake enables time travel, allowing users to query previous versions of data.

```sql
-- View the history of a table
DESCRIBE HISTORY Medals;
```

```python
# Querying a previous version using PySpark
previous_version = spark.read.format("delta").option("versionAsOf", 2).load(f"{gold}/Delta/Medals")
previous_version.show()
```

### **Versioning in Delta Lake**
Every change to a Delta table is stored as a new version, maintaining data lineage and reproducibility.

```python
# Get the latest version number
latest_version = spark.sql("SELECT max(version) FROM (DESCRIBE HISTORY Medals)")
print(f"Latest Version: {latest_version}")
```

### **ACID Transactions & Schema Evolution**
Delta Lake ensures **ACID compliance** (Atomicity, Consistency, Isolation, Durability) and supports schema evolution.

```sql
-- Enforce schema constraints and enable column mapping
ALTER TABLE Athlete
SET TBLPROPERTIES (
    'delta.minReaderVersion' = '2',
    'delta.minWriterVersion' = '5',
    'delta.columnMapping.mode' = 'name'
);
```

---

## üìä Power BI Dashboard

- **Total Medals**: `SUM(Medals[Total])`
- **Gold Medals**: `SUM(Medals[Gold])`
- **Silver Medals**: `SUM(Medals[Silver])`
- **Bronze Medals**: `SUM(Medals[Bronze])`
- **Total Athletes**: `CALCULATE(DISTINCTCOUNT('Athletes'[Name]))`

---

This structured approach ensures efficient processing, data integrity, and insightful analysis of Olympics data. üöÄ
